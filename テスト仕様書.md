# テスト計画（Test Plan）

## 1. 目的・背景
- ビジネス要件と品質目標の整合  
- リリーススケジュールとのマイルストーン設定  
- 品質評価基準（欠陥許容数、カバレッジ目標）の明示
- 品質指標（Quality Metrics）

品質を可視化し、継続的に改善するために使う代表的な指標を「テストプロセス」「欠陥・障害」「プロダクト」「コード品質」「開発プロセス」の５つに分類してまとめます。

---

## 1. テストプロセス指標

| 指標                      | 説明                                               | 計算式例                                        | 目標・頻度        |
|-------------------------|--------------------------------------------------|-----------------------------------------------|-----------------|
| テストカバレッジ           | テストで網羅されたコード／機能の割合                         | (実行済みテストケース数／総テストケース数)×100% | ≥ 90％／週次      |
| テスト自動化率             | 自動化されたテストケースの割合                          | (自動化テスト数／全テスト数)×100%               | ≥ 70％／月次      |
| テスト進捗率               | 予定テスト数に対する実施済みテスト数の進捗                  | (実施済みテスト数／予定テスト数)×100%           | 100％／日次      |
| 回帰テスト検出率           | 回帰テストで再発不具合を検出した割合                      | (回帰で検出した不具合数／回帰実施時不具合数)×100% | 高いほど○／リリース毎 |

**ポイント**  
- カバレッジが高くても質の低いテストばかりなら意味がないので、異常系テストの割合も併せて見る。  
- 自動化率は立ち上げコストとメンテナンスコストのバランスを評価。

---

## 2. 欠陥・障害指標

| 指標            | 説明                                         | 計算式                                          | 目標・頻度        |
|---------------|--------------------------------------------|-----------------------------------------------|-----------------|
| 欠陥密度         | 一定規模あたりの不具合数                            | 不具合数／（KLOC、FP、機能数）                 | ≤ 1件／KLOC／リリース |
| 欠陥発見率       | テスト段階で検出できた不具合の割合                     | (テスト段階検出数／総検出不具合数)×100%         | ≥ 80％／リリース   |
| 欠陥漏れ率       | テスト終了後にユーザー報告された不具合の割合              | (運用後不具合数／総不具合数)×100%               | ≤ 5％／リリース    |
| 平均修正時間（MTTR） | 不具合報告から修正完了までの平均時間（時間単位）            | Σ(修正完了時間–報告時間)／不具合数             | ≤ 48時間／月次     |
| 平均故障間隔（MTBF） | 障害と障害の間の平均稼働時間                           | 総稼働時間／障害回数                            | 業界標準以上／四半期  |

**ポイント**  
- 欠陥密度は開発初期に、漏れ率は受入後・運用開始後に特に重視。  
- MTTR／MTBFは可用性向上と運用負荷低減の鍵。

---

## 3. プロダクト品質指標

| 指標                 | 説明                                      | 計算式                                               | 目標・頻度         |
|--------------------|-----------------------------------------|----------------------------------------------------|------------------|
| ユーザー障害発生率      | 全ユーザーあたりの障害発生数                          | 障害件数／MAU（月間アクティブユーザー数）              | 業界ベンチマーク以下／月次 |
| お客様満足度（CSAT）   | 製品品質に対するユーザー評価                         | アンケート調査平均スコア                                    | ≥ 4.0／5点／四半期   |
| SLA準拠率             | 定めたサービスレベルを満たしたリクエストの割合               | (SLA内応答数／総リクエスト数)×100%                      | 99.9%以上／月次     |
| セキュリティ欠陥件数    | 脆弱性スキャンやペネトレーションテストで検出された対策未済脆弱性数 | 脆弱性件数                                          | 0件／四半期        |

**ポイント**  
- 実運用データを元にリアルタイムで追うことで、品質トレンドの早期察知が可能に。  
- CSATはNPS（Net Promoter Score）やCES（Customer Effort Score）と合わせても有効。

---

## 4. コード品質指標

| 指標                    | 説明                                | ツール例                        | 目標・頻度       |
|-----------------------|-----------------------------------|------------------------------|----------------|
| サイクロマティック複雑度    | コードの分岐・複雑さ。高いほどバグリスク増         | SonarQube、PMD              | 関数あたり ≤ 10／CI毎 |
| テクニカルデット（債務）   | レビューで指摘された未解決のコード品質要改善項目       | CodeClimate、SonarQube      | 優先度高 0件／月次 |
| コードレビューカバレッジ    | プルリクエスト数に対するレビュー実施数             | GitHub/GitLab標準機能       | 100%／PR毎      |
| 重複コード率             | 同一ロジックのコピー量                         | SonarQube、DupFinder        | ≤ 3%／CI毎      |

**ポイント**  
- 複雑度は低

## 2. スコープ
- テスト対象機能一覧（画面、API、バッチなど）  
- 非対象機能とその理由  
- テストレベル：単体／結合／システム／受入

## 3. アプローチ
- テストタイプ  
  - 機能テスト、回帰テスト、セキュリティテスト、パフォーマンステスト  
- 設計技法  
  - 同値クラステスト、境界値分析、状態遷移テスト、ユースケーステスト  
- 自動化範囲  
  - スモークテスト、回帰テスト、データ駆動テスト

## 4. テスト環境・ツール
- HW/SW構成リスト（OS、DB、ミドルウェア、ブラウザ）  
- 仮想環境 vs 実機環境  
- テスト管理：Jira／TestRail／Zephyr  
- 自動化：Selenium／Appium／JMeter

## 5. リソース＆スケジュール
- 役割分担（TM／TL／Tester／Automation Engineer）  
- マイルストーン（設計完了、実行、レポート）  
- バッファ・依存関係の明示

## 6. 入退出基準
- 入り基準：要件凍結、環境立ち上げ完了、テスト設計完了  
- 出口基準：重大欠陥クローズ、カバレッジ95%以上

## 7. リスク＆緩和策
- 要件変更リスク → 仕様凍結ガバナンス  
- 環境障害リスク → バックアップ環境準備  
- 人員不足リスク → クロストレーニング

## 8. 成果物
- テスト計画書、テストケース一式、テスト報告書、欠陥レポート

---

# 不具合分析（Defect Analysis）

## A. 登録〜優先度付与
1. Defect レコード項目  
   - ID／概要／詳細説明  
   - 発生日時／発見者／担当者  
   - 重大度 (D0–D4)／優先度 (P0–P3)／ステータス  
2. 環境情報  
   - OS／DB／ミドルウェア／ブラウザとバージョン

## B. 再現手順・影響範囲
- 環境セットアップ手順  
- 操作手順→期待結果 vs 実結果  
- 影響範囲：上下流モジュール、関連API

## C. 原因分析
- 5 Why  
- Fishbone（人・方法・機器・材料・測定・環境）

## D. 再発防止策
- テストケース追加／レビュー強化  
- 設計書・仕様書の明確化  
- 静的解析ツール導入（SonarQube等）

## E. レポート・管理
- 定期傾向分析（週次／月次レポート）  
- KPTやレビュー会議でナレッジ共有

---

# 単体テスト仕様書（Unit Test Specification）

## 1. テンプレート

| ケースID | モジュール | メソッド／関数 | 前提条件 | 入力値 | 手順 | 期待結果 | 実結果 | 判定 | 備考 |
|---|---|---|---|---|---|---|---|---|---|

## 2. テスト観点
- 正常系：典型値、複数入力型  
- 異常系：Null、空文字、オーバーフロー、例外  
- 境界値：最小値–最大値  
- 例外処理パス：try/catch、カスタム例外

## 3. モック／スタブ
- 外部依存（DB、API、ファイルI/O）の切り離し  
- フレームワーク：Mockito、JMockit、FakeIt  
- スタブ vs モック vs スパイの使い分け

## 4. カバレッジ
- ステートメント／ブランチ／条件／パスカバレッジ  
- ツール：JaCoCo、Cobertura、Istanbul

## 5. 自動化
- CI連携：Jenkins、GitHub Actions  
- レポート形式：JUnit XML、HTML

---

# 結合テスト仕様書（Integration Test Specification）

## 1. テストマトリクス

| テストID | モジュールA–B | インタフェース | 種別 | 正常/異常 | 前提条件 | 手順 | 期待結果 |
|---|---|---|---|---|---|---|---|

## 2. シナリオ設計
- E2Eフロー：画面→API→DB  
- データ駆動：CSV/JSONテストデータ  
- マルチモジュール連携ケース

## 3. インタフェース検証
- リクエスト/レスポンススキーマ  
- 型チェック、必須項目検証

## 4. エラー／例外ハンドリング
- タイムアウト／リトライ／フォールバック  
- ネットワーク障害シミュレーション

## 5. 外部連携
- Service Virtualization  
- 認証／認可トークンフロー

## 6. バージョン互換性
- 後方互換／前方互換テストシナリオ

---

# 次に深掘りしたいトピック
- システムテスト（性能・負荷・セキュリティ）設計  
- テスト自動化フレームワーク（POM、BDD）  
- 品質ゲート（SonarQube／OWASP ZAP連携）  
- 品質指標（MTTR、MTBF、テストカバレッジ）  
- Shift-Left／Shift-Rightテスト戦略  
